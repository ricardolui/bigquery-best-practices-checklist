{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Best Practices: FinOps & Cost Allocation\n",
    "\n",
    "**Contributors:**\n",
    "*   Google Cloud Data Analytics Team\n",
    "*   XXXXXX - Brazil DA CE - xxxx@google.com\n",
    "*   XXXXXX - Brazil DA CE - xxxx@google.com\n",
    "*   XXXXXX - Mexico DA CE - xxxx@google.com   \n",
    "*   XXXXXX - Peru DA CE - xxxx@google.com\n",
    "*   XXXXXX - Colombia DA CE - xxx@google.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize gcloud for authentication in the notebook\n",
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bigframes.pandas as bpd\n",
    "from google.cloud import bigquery\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize BigQuery Client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = client.project  # Uses default project from environment\n",
    "REGION = \"region-us\" # UPDATE THIS to your dataset region (e.g., region-eu, region-us-central1)\n",
    "GEMINI_MODEL_NAME = \"gemini-3-pro-preview\" # Updated to use gemini-3-pro-preview\n",
    "VERTEX_AI_LOCATION = \"global\" # Vertex AI location for Gemini models\n",
    "GEMINI_ENDPOINT_URL = f\"https://aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{VERTEX_AI_LOCATION}/publishers/google/models/{GEMINI_MODEL_NAME}\"\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Region: {REGION}\")\n",
    "print(f\"Gemini Endpoint: {GEMINI_ENDPOINT_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Pre-requirements\n",
    "\n",
    "This section sets up the necessary prerequisites for the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Create Gemini Model\n",
    "\n",
    "Create a BQML Remote Model that uses the Gemini model via DEFAULT connection for AI-powered recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_sql = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `bq_bestpractices_checklist.gemini`\n",
    "REMOTE WITH CONNECTION DEFAULT\n",
    "OPTIONS (endpoint = '{GEMINI_ENDPOINT_URL}')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    job = client.query(create_model_sql)\n",
    "    job.result()\n",
    "    print(\"Model created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Create Organization-level View\n",
    "\n",
    "Create a dataset and a view that aggregates jobs from the top 20 projects in the organization. This view will be used as the source for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_query = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS bq_bestpractices_checklist;\n",
    "\n",
    "EXECUTE IMMEDIATE (\n",
    "  (\n",
    "    SELECT\n",
    "      'CREATE OR REPLACE VIEW `bq_best_practices_checklist.jobs_by_top_20_projects` AS (' ||\n",
    "      STRING_AGG(\n",
    "        'SELECT * FROM `' || project_id || '.region-us.INFORMATION_SCHEMA.JOBS_BY_PROJECT`',\n",
    "        ' UNION ALL '\n",
    "      ) || ')'\n",
    "    FROM (\n",
    "      SELECT\n",
    "        project_id\n",
    "      FROM\n",
    "        `region-us.INFORMATION_SCHEMA.JOBS_BY_ORGANIZATION`\n",
    "      WHERE \n",
    "        creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL(30, DAY))\n",
    "      GROUP BY\n",
    "        1\n",
    "      ORDER BY\n",
    "        SUM(total_slot_ms) DESC\n",
    "      LIMIT\n",
    "        20\n",
    "    )\n",
    "  )\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    job = client.query(setup_query)\n",
    "    job.result()\n",
    "    print(\"Dataset and View created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating view: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook implements the technical validation for the **FinOps & Cost Allocation** pillar of the BigQuery Health Check.\n",
    "\n",
    "### Key Focus Areas:\n",
    "1.  **Billing Export Readiness**: Check if a dataset specifically for billing export exists.\n",
    "2.  **Label Coverage Analysis**: Calculate the percentage of slots and storage bytes that are \"Unattributed\" (missing labels).\n",
    "3.  **Chargeback Modeling**: Simulate a chargeback invoice by aggregating costs by User/Principal.\n",
    "4.  **Commitment Gap Analysis**: Compare average slot usage vs. purchased commitments to identify over-provisioning or opportunities for CUDs.\n",
    "5.  **AI-Powered Recommendations**: Generate actionable insights using Gemini.\n",
    "\n",
    "### Prerequisites\n",
    "*   Permissions to view `INFORMATION_SCHEMA.JOBS_BY_PROJECT` and `INFORMATION_SCHEMA.CAPACITY_COMMITMENTS`.\n",
    "*   BigQuery API enabled.\n",
    "*   Vertex AI API enabled (for Gemini recommendations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Billing Export Readiness\n",
    "Check if a dataset specifically for billing export exists. If not, we provide instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery billing_datasets_df\n",
    "SELECT\n",
    "    schema_name,\n",
    "    creation_time,\n",
    "    location\n",
    "FROM\n",
    "    INFORMATION_SCHEMA.SCHEMATA\n",
    "WHERE\n",
    "    schema_name LIKE '%billing%'\n",
    "    OR schema_name LIKE '%export%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if billing_datasets_df.empty:\n",
    "    print(\"WARNING: No obvious billing export datasets found (searching for 'billing' or 'export' in name).\")\n",
    "    print(\"Recommendation: Enable Cloud Billing export to BigQuery for granular cost analysis.\")\n",
    "    print(\"Instructions: https://cloud.google.com/billing/docs/how-to/export-data-bigquery\")\n",
    "else:\n",
    "    print(\"Potential billing datasets found:\")\n",
    "    print(billing_datasets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Label Coverage Analysis\n",
    "Calculate the percentage of slots and storage bytes that are \"Unattributed\" (missing labels). This helps in identifying how much of the workload is not being tracked for chargeback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery label_coverage_df\n",
    "WITH JobLabels AS (\n",
    "    SELECT\n",
    "        job_id,\n",
    "        total_bytes_billed,\n",
    "        total_slot_ms,\n",
    "        (SELECT COUNT(*) FROM UNNEST(job_labels)) AS label_count\n",
    "    FROM\n",
    "        `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT -- Adjust region if necessary\n",
    "    WHERE\n",
    "        creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)\n",
    "    )\n",
    "SELECT\n",
    "    COUNT(*) AS total_jobs,\n",
    "    SUM(CASE WHEN label_count = 0 THEN 1 ELSE 0 END) AS jobs_without_labels,\n",
    "    ROUND(SAFE_DIVIDE(SUM(CASE WHEN label_count = 0 THEN total_bytes_billed ELSE 0 END), SUM(total_bytes_billed)) * 100, 2) AS pct_bytes_unlabeled,\n",
    "    ROUND(SAFE_DIVIDE(SUM(CASE WHEN label_count = 0 THEN total_slot_ms ELSE 0 END), SUM(total_slot_ms)) * 100, 2) AS pct_slots_unlabeled\n",
    "FROM\n",
    "    JobLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Label Coverage\n",
    "print(\"Label Coverage Analysis (Last 30 Days):\")\n",
    "display(label_coverage_df)\n",
    "\n",
    "if not label_coverage_df.empty and label_coverage_df['pct_bytes_unlabeled'].iloc[0] > 20:\n",
    "    print(\"\\nALERT: Significant portion of bytes billed (>20%) is unlabeled. Implement a mandatory labeling policy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chargeback Modeling\n",
    "Simulate a chargeback invoice by aggregating costs by User/Principal. We assume a standard on-demand rate ($5/TB) for estimation purposes if pricing data isn't directly available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery chargeback_df\n",
    "SELECT\n",
    "    user_email,\n",
    "    COUNT(job_id) as job_count,\n",
    "    ROUND(SUM(total_bytes_billed) / POW(1024, 4) * 5, 2) AS estimated_cost_usd, -- $5 per TB assumption\n",
    "    ROUND(SUM(total_slot_ms) / (1000 * 60 * 60), 2) AS total_slot_hours\n",
    "FROM\n",
    "    `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT\n",
    "WHERE\n",
    "    creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    estimated_cost_usd DESC\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Top Spenders\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=chargeback_df, x='estimated_cost_usd', y='user_email')\n",
    "plt.title('Top 10 Users by Estimated Cost (Last 30 Days)')\n",
    "plt.xlabel('Estimated Cost (USD)')\n",
    "plt.ylabel('User Email')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Commitment Gap Analysis\n",
    "Compare average slot usage vs. purchased commitments to identify over-provisioning or opportunities for CUDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery commitment_gap_df\n",
    "WITH Usage AS (\n",
    "    SELECT\n",
    "        TIMESTAMP_TRUNC(creation_time, HOUR) as usage_hour,\n",
    "        SUM(total_slot_ms) / (1000 * 60 * 60) as slot_hours_used\n",
    "    FROM\n",
    "        `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECT\n",
    "    WHERE\n",
    "        creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)\n",
    "    GROUP BY 1\n",
    "),\n",
    "Commitments AS (\n",
    "    SELECT\n",
    "        SUM(slot_count) as total_slots_committed\n",
    "    FROM\n",
    "        `region-us`.INFORMATION_SCHEMA.CAPACITY_COMMITMENTS\n",
    "    WHERE\n",
    "        state = 'ACTIVE'\n",
    ")\n",
    "SELECT\n",
    "    u.usage_hour,\n",
    "    u.slot_hours_used,\n",
    "    c.total_slots_committed,\n",
    "    (c.total_slots_committed - u.slot_hours_used) as unused_slots\n",
    "FROM\n",
    "    Usage u\n",
    "CROSS JOIN\n",
    "    Commitments c\n",
    "ORDER BY\n",
    "    u.usage_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not commitment_gap_df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(commitment_gap_df['usage_hour'], commitment_gap_df['slot_hours_used'], label='Slot Usage')\n",
    "    plt.axhline(y=commitment_gap_df['total_slots_committed'].iloc[0], color='r', linestyle='--', label='Committed Slots')\n",
    "    plt.title('Slot Usage vs Commitment (Last 7 Days)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Slots')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No usage data found for commitment gap analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. AI-Powered Recommendations\n",
    "Using Gemini to analyze the gathered metrics and provide actionable recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare summary string for Gemini\n",
    "summary_text = f\"\"\"\n",
    "Analyze the following metrics regarding FinOps & Cost Allocation:\n",
    "1. Label Coverage: {label_coverage_df.to_dict('records') if not label_coverage_df.empty else 'No data'}\n",
    "2. Top Spenders: {chargeback_df.head(3).to_dict('records') if not chargeback_df.empty else 'No data'}\n",
    "3. Commitment Gap: {commitment_gap_df.describe().to_dict() if not commitment_gap_df.empty else 'No data'}\n",
    "\n",
    "Provide 3 actionable recommendations on topic FinOps & Cost Allocation.\n",
    "\"\"\"\n",
    "\n",
    "# Call Gemini (assuming a remote model 'gemini_pro' exists in dataset 'ml_dataset')\n",
    "# Note: You need to replace 'your_project.ml_dataset.gemini_pro' with your actual model path\n",
    "model_id = 'gemini_pro' # Placeholder, user should update\n",
    "\n",
    "print(\"Sending the following context to Gemini for analysis:\")\n",
    "print(summary_text)\n",
    "\n",
    "# In a real scenario, you would run:\n",
    "# df_result = client.query(f\"SELECT ml_generate_text_result FROM ML.GENERATE_TEXT(MODEL `{model_id}`, (SELECT '{summary_text}' AS prompt))\").to_dataframe()\n",
    "# print(df_result['ml_generate_text_llm_result'].iloc[0])\n",
    "\n",
    "print(\"\\n[Mock Output] Gemini Recommendations:\")\n",
    "print(\"1. Implement a strict tagging policy to reduce unattributed costs.\")\n",
    "print(\"2. Review top spenders and optimize their most expensive queries using partitioning/clustering.\")\n",
    "print(\"3. Consider purchasing Committed Use Discounts (CUDs) to cover the baseline slot usage observed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbformat": 4,
  "nbformat_minor": 5
 }
}