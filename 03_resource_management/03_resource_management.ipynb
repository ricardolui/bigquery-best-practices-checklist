{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWADW9i04yjb"
   },
   "source": [
    "# BigQuery Best Practices: Resource Management\n",
    "\n",
    "**Objective:** Identify bottlenecks caused by slot contention, evaluate the suitability of the current pricing model (On-Demand vs. Editions), ensure critical pipelines have dedicated resources, and reduce operational noise.\n",
    "\n",
    "**Contributors:**\n",
    "*   Google Cloud Data Analytics Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qa8_yvRK4yjc"
   },
   "outputs": [],
   "source": [
    "# Initialize gcloud for authentication in the notebook\n",
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bigframes.pandas as bpd\n",
    "from google.cloud import bigquery\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize BigQuery Client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Configuration\n",
    "PROJECT_ID = client.project  # Uses default project from environment\n",
    "REGION = \"region-us\" # UPDATE THIS to your dataset region (e.g., region-eu, region-us-central1)\n",
    "GEMINI_MODEL_NAME = \"gemini-3-pro-preview\" # Updated to use gemini-3-pro-preview\n",
    "VERTEX_AI_LOCATION = \"global\" # Vertex AI location for Gemini models\n",
    "GEMINI_ENDPOINT_URL = f\"https://aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{VERTEX_AI_LOCATION}/publishers/google/models/{GEMINI_MODEL_NAME}\"\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Region: {REGION}\")\n",
    "print(f\"Gemini Endpoint: {GEMINI_ENDPOINT_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Pre-requirements\n",
    "\n",
    "This section sets up the necessary prerequisites for the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Create Gemini Model\n",
    "\n",
    "Create a BQML Remote Model that uses the Gemini model via DEFAULT connection for AI-powered recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_sql = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `bq_bestpractices_checklist.gemini`\n",
    "REMOTE WITH CONNECTION DEFAULT\n",
    "OPTIONS (endpoint = '{GEMINI_ENDPOINT_URL}')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    job = client.query(create_model_sql)\n",
    "    job.result()\n",
    "    print(\"Model created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Create Organization-level View\n",
    "\n",
    "Create a dataset and a view that aggregates jobs from the top 20 projects in the organization. This view will be used as the source for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_query = \"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS bq_bestpractices_checklist;\n",
    "\n",
    "EXECUTE IMMEDIATE (\n",
    "  (\n",
    "    SELECT\n",
    "      'CREATE OR REPLACE VIEW `bq_best_practices_checklist.jobs_by_top_20_projects` AS (' ||\n",
    "      STRING_AGG(\n",
    "        'SELECT * FROM `' || project_id || '.region-us.INFORMATION_SCHEMA.JOBS_BY_PROJECT`',\n",
    "        ' UNION ALL '\n",
    "      ) || ')'\n",
    "    FROM (\n",
    "      SELECT\n",
    "        project_id\n",
    "      FROM\n",
    "        `region-us.INFORMATION_SCHEMA.JOBS_BY_ORGANIZATION`\n",
    "      WHERE \n",
    "        creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL(30, DAY))\n",
    "      GROUP BY\n",
    "        1\n",
    "      ORDER BY\n",
    "        SUM(total_slot_ms) DESC\n",
    "      LIMIT\n",
    "        20\n",
    "    )\n",
    "  )\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    job = client.query(setup_query)\n",
    "    job.result()\n",
    "    print(\"Dataset and View created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating view: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhkKOjtC4yjd"
   },
   "source": [
    "## 1. On-Demand vs. Slot Pricing Comparison\n",
    "\n",
    "**Objective:** Determine if queries should run on On-Demand or Autoscaling Slots (Editions).\n",
    "**Methodology:** Compare theoretical On-Demand cost ($6.25/TiB) vs. Slot cost ($0.06/slot-hour).\n",
    "**Success Criteria:** Identify queries where switching to Slots is >20% cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "VaOE1Il94yjd",
    "outputId": "8192e9ee-86d3-4045-a779-e451609b5f43"
   },
   "outputs": [],
   "source": [
    "query_pricing_comparison = f'''\n",
    "SELECT\n",
    "  project_id,  -- Added project_id\n",
    "  job_id,\n",
    "  creation_time,\n",
    "  user_email,\n",
    "  total_bytes_billed,\n",
    "  total_slot_ms,\n",
    "  -- On-Demand Cost: $6.25 per TiB (US Multi-region)\n",
    "  (total_bytes_billed / POW(1024, 4)) * 6.25 AS estimated_on_demand_cost,\n",
    "  -- Slot Cost: $0.06 per slot-hour (Approx. Enterprise Standard)\n",
    "  (total_slot_ms / (1000 * 3600)) * 0.06 AS estimated_slot_cost,\n",
    "  query\n",
    "FROM\n",
    "  `{PROJECT_ID}.bq_bestpractices_checklist.jobs_by_top_20_projects`\n",
    "WHERE\n",
    "  creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)\n",
    "  AND job_type = 'QUERY'\n",
    "  AND total_bytes_billed > 0\n",
    "ORDER BY\n",
    "  estimated_on_demand_cost DESC\n",
    "LIMIT 100\n",
    "'''\n",
    "\n",
    "df_pricing = client.query(query_pricing_comparison).to_dataframe()\n",
    "\n",
    "# Apply logic: Switch to SLOT if slot cost is at least 20% cheaper than on-demand\n",
    "df_pricing['recommendation'] = 'KEEP_ON_DEMAND'\n",
    "df_pricing.loc[df_pricing['estimated_slot_cost'] < (df_pricing['estimated_on_demand_cost'] * 0.8), 'recommendation'] = 'SWITCH_TO_SLOTS'\n",
    "\n",
    "print(\"Pricing Model Comparison (Top 10 High Cost Queries):\")\n",
    "df_pricing[['job_id', 'estimated_on_demand_cost', 'estimated_slot_cost', 'recommendation']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIOcVP714yjd",
    "outputId": "3c280813-70c8-4479-c25b-e6effff26158"
   },
   "outputs": [],
   "source": [
    "# Aggregated Analysis: Total Cost Comparison\n",
    "total_on_demand_cost = df_pricing['estimated_on_demand_cost'].sum()\n",
    "total_slot_cost = df_pricing['estimated_slot_cost'].sum()\n",
    "\n",
    "print(f\"Total Estimated On-Demand Cost: ${total_on_demand_cost:,.2f}\")\n",
    "print(f\"Total Estimated Slot Cost:      ${total_slot_cost:,.2f}\")\n",
    "\n",
    "if total_slot_cost < (total_on_demand_cost * 0.8):\n",
    "    savings = total_on_demand_cost - total_slot_cost\n",
    "    print(f\"\\nRecommendation: SWITCH TO SLOTS. Potential savings: ${savings:,.2f} ({(savings/total_on_demand_cost)*100:.1f}%)\")\n",
    "elif total_slot_cost > total_on_demand_cost:\n",
    "    extra_cost = total_slot_cost - total_on_demand_cost\n",
    "    print(f\"\\nRecommendation: KEEP ON-DEMAND. Slots are estimated to be ${extra_cost:,.2f} more expensive.\")\n",
    "else:\n",
    "    print(\"\\nRecommendation: MIXED / NEUTRAL. Costs are comparable. Analyze specific high-cost queries for partial migration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj5e_Uik4yjd"
   },
   "source": [
    "**Recommendation:** For queries marked `SWITCH_TO_SLOTS`, consider moving them to a project/reservation using BigQuery Editions (Autoscaling) to save costs."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n--- Aggregated Analysis by Project ID ---\\n\")\n",
    "df_grouped_by_project = df_pricing.groupby('project_id').agg(\n",
    "    total_estimated_on_demand_cost=('estimated_on_demand_cost', 'sum'),\n",
    "    total_estimated_slot_cost=('estimated_slot_cost', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "def get_project_recommendation(row):\n",
    "    on_demand_cost = row['total_estimated_on_demand_cost']\n",
    "    slot_cost = row['total_estimated_slot_cost']\n",
    "\n",
    "    if slot_cost < (on_demand_cost * 0.8):\n",
    "        return 'SWITCH_TO_SLOTS'\n",
    "    elif slot_cost > on_demand_cost:\n",
    "        return 'KEEP_ON_DEMAND'\n",
    "    else:\n",
    "        return 'MIXED / NEUTRAL'\n",
    "\n",
    "df_grouped_by_project['recommendation'] = df_grouped_by_project.apply(get_project_recommendation, axis=1)\n",
    "\n",
    "print(df_grouped_by_project)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hmcgRXcentwY",
    "outputId": "4c9f2da9-7569-4123-8a74-ea9f6f05ad9b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgjnMfYI4yjd"
   },
   "source": [
    "## 2. Slot Contention Analysis\n",
    "\n",
    "**Objective:** Identify \"Pending\" states caused by slot starvation.\n",
    "**Methodology:** Analyze `avg_pending_ms` for jobs.\n",
    "**Success Criteria:** Minimize pending time for critical jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "Awxt0gPS4yjd",
    "outputId": "4ae209e5-bee5-4304-cfca-fd6aefbbc03c"
   },
   "outputs": [],
   "source": [
    "query_contention = f\"\"\"\n",
    "SELECT\n",
    "  project_id,\n",
    "  job_type,\n",
    "  COUNT(*) as total_jobs,\n",
    "  AVG(TIMESTAMP_DIFF(start_time, creation_time, MILLISECOND)) as avg_pending_ms,\n",
    "  MAX(TIMESTAMP_DIFF(start_time, creation_time, MILLISECOND)) as max_pending_ms\n",
    "FROM\n",
    "  `{PROJECT_ID}.bq_bestpractices_checklist.jobs_by_top_20_projects`\n",
    "WHERE\n",
    "  creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)\n",
    "  AND state = 'DONE'\n",
    "GROUP BY 1, 2\n",
    "HAVING avg_pending_ms > 1000\n",
    "ORDER BY avg_pending_ms DESC\n",
    "\"\"\"\n",
    "\n",
    "df_contention = client.query(query_contention).to_dataframe()\n",
    "print(\"Jobs with significant pending time (potential slot starvation):\")\n",
    "df_contention.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82PdsstT4yjd"
   },
   "source": [
    "**Recommendation:** If `avg_pending_ms` is high, consider increasing max slots (if autoscaling) or baseline slots (if fixed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5s5w17z4yjd"
   },
   "source": [
    "## 3. Max Autoscaling Recommendation\n",
    "\n",
    "**Objective:** Recommend a `max_autoscaling` value for reservations based on historical slot usage.\n",
    "**Methodology:** Calculate the average slot usage per minute and then determine various percentiles (P95, P90, P85, P75, P50) of these per-minute averages.\n",
    "**Success Criteria:** Provide data-driven recommendations for setting `max_autoscaling` to balance cost and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "8qNEEEXY4yjd",
    "outputId": "bac9bc40-7fe3-4eda-b667-4e89da088147"
   },
   "outputs": [],
   "source": [
    "query_max_autoscaling = f'''\n",
    "WITH per_minute_avg_slots AS (\n",
    "  SELECT\n",
    "    DATE_TRUNC(job_creation_time, MINUTE) AS minute_start,\n",
    "    AVG(period_slot_ms) AS avg_slots_per_minute\n",
    "  FROM\n",
    "    `region-us`.INFORMATION_SCHEMA.JOBS_TIMELINE_BY_ORGANIZATION\n",
    "  WHERE\n",
    "    job_creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)\n",
    "  GROUP BY\n",
    "    1\n",
    ")\n",
    "SELECT\n",
    "  APPROX_QUANTILES(avg_slots_per_minute, 100)[OFFSET(95)] / 1000 AS p95_slots_per_minute,\n",
    "  APPROX_QUANTILES(avg_slots_per_minute, 100)[OFFSET(90)] / 1000 AS p90_slots_per_minute,\n",
    "  APPROX_QUANTILES(avg_slots_per_minute, 100)[OFFSET(85)] / 1000 AS p85_slots_per_minute,\n",
    "  APPROX_QUANTILES(avg_slots_per_minute, 100)[OFFSET(75)] / 1000 AS p75_slots_per_minute,\n",
    "  APPROX_QUANTILES(avg_slots_per_minute, 100)[OFFSET(60)] / 1000 AS p60_slots_per_minute,\n",
    "  APPROX_QUANTILES(avg_slots_per_minute, 100)[OFFSET(50)] / 1000 AS p50_slots_per_minute,\n",
    "  MAX(avg_slots_per_minute) / 1000 AS max_slots_per_minute,\n",
    "  AVG(avg_slots_per_minute) / 1000 AS avg_slots_per_minute_total\n",
    "FROM per_minute_avg_slots\n",
    "'''\n",
    "\n",
    "df_max_autoscaling = client.query(query_max_autoscaling).to_dataframe()\n",
    "print(\"Max Autoscaling Recommendation Metrics:\")\n",
    "df_max_autoscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Recommendation:** The calculated percentiles of average slots per minute provide insights for setting `max_autoscaling` for reservations:\n",
    "-   **P95:** A good starting point for `max_autoscaling` if you want to ensure high performance and minimize queueing for 95% of the time, accepting higher costs.\n",
    "-   **P90:** A balance between performance and cost. Setting `max_autoscaling` to this value would cover 90% of your peak minute slot demands.\n",
    "-   **P85:** Another balanced option, covering 85% of your peak minute slot demands.\n",
    "-   **P75:** A more cost-effective option, covering 75% of your peak minute slot demands, potentially with more frequent queueing during higher peaks.\n",
    "-   **P50:** The most cost-effective option, covering 50% of your peak minute slot demands, which will likely lead to significant queueing during peak periods.\n",
    "\n",
    "Choose a percentile that aligns with your Service Level Objectives (SLOs) and cost optimization goals."
   ],
   "metadata": {
    "id": "1ncR5s1RsF19"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxITsE1K4yjd"
   },
   "source": [
    "**Recommendation:** The calculated percentiles of average slots per minute provide insights for setting `max_autoscaling` for reservations:\n",
    "-   **P95:** A good starting point for `max_autoscaling` if you want to ensure high performance and minimize queueing for 95% of the time, accepting higher costs.\n",
    "-   **P90:** A balance between performance and cost. Setting `max_autoscaling` to this value would cover 90% of your peak minute slot demands.\n",
    "-   **P85:** Another balanced option, covering 85% of your peak minute slot demands.\n",
    "-   **P75:** A more cost-effective option, covering 75% of your peak minute slot demands, potentially with more frequent queueing during higher peaks.\n",
    "-   **P50:** The most cost-effective option, covering 50% of your peak minute slot demands, which will likely lead to significant queueing during peak periods.\n",
    "\n",
    "Choose a percentile that aligns with your Service Level Objectives (SLOs) and cost optimization goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liuaUxBF4yjd"
   },
   "source": [
    "**Recommendation:** Ensure production projects are assigned to specific reservations, not just the `default` pool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itCPpNQX4yjd"
   },
   "source": [
    "## 4. Error Analysis\n",
    "\n",
    "**Objective:** Reduce operational noise and retries.\n",
    "**Methodology:** Summarize top error codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "YmRSaxyA4yjd",
    "outputId": "c3f9189c-89ff-45b7-a6b3-a62670630a28"
   },
   "outputs": [],
   "source": [
    "query_errors = f\"\"\"\n",
    "SELECT\n",
    "  error_result.reason as error_reason,\n",
    "  COUNT(*) as error_count\n",
    "FROM\n",
    "  `region-us`.INFORMATION_SCHEMA.JOBS_BY_ORGANIZATION\n",
    "WHERE\n",
    "  creation_time > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)\n",
    "  AND error_result IS NOT NULL\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "df_errors = client.query(query_errors).to_dataframe()\n",
    "print(\"Top Error Codes:\")\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXHzCKne4yjd"
   },
   "source": [
    "**Recommendation:** Address top errors. For `rateLimitExceeded`, implement backoff. For `resourcesExceeded`, increase slots or optimize queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCu8r4mh4yjd"
   },
   "source": [
    "## 6. Google Cloud Recommendations\n",
    "\n",
    "**Objective:** Review automated recommendations provided by Google Cloud.\n",
    "**Methodology:** Query `INFORMATION_SCHEMA.RECOMMENDATIONS_BY_ORGANIZATION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZqgcvPh-4yje",
    "outputId": "ebba03c0-7c2d-4f47-c846-9f3a3811263f"
   },
   "outputs": [],
   "source": [
    "query_recommendations = f\"\"\"\n",
    "SELECT\n",
    "  project_id,\n",
    "  recommender,\n",
    "  subtype,\n",
    "  LAX_INT64(additional_details.overview.bytesSavedMonthly) / POW(1024, 3) as est_gb_saved_monthly,\n",
    "  LAX_INT64(additional_details.overview.slotMsSavedMonthly) / (1000 * 3600) as slot_hours_saved_monthly,\n",
    "  last_updated_time\n",
    "FROM\n",
    " `region-us`.INFORMATION_SCHEMA.RECOMMENDATIONS_BY_ORGANIZATION\n",
    "WHERE\n",
    "  recommender LIKE '%capacity%' OR recommender LIKE '%slot%'\n",
    "ORDER BY\n",
    "  slot_hours_saved_monthly DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df_recommendations = client.query(query_recommendations).to_dataframe()\n",
    "    print(\"Top Google Cloud Resource Recommendations:\")\n",
    "    df_recommendations.head()\n",
    "except Exception as e:\n",
    "    print(\"Error querying Recommendations.\", e)\n",
    "    df_recommendations = pd.DataFrame() # Empty DF for summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCIa7shF4yje"
   },
   "source": [
    "**Recommendation:** Review capacity-related recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Afn8CssK4yje"
   },
   "source": [
    "## 7. AI-Powered Recommendations\n",
    "\n",
    "**Objective:** Use Generative AI to synthesize findings.\n",
    "**Methodology:** Summarize findings and use Gemini Pro via BQML."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE MODEL `bq_bestpractices_checklist.gemini`\n",
    "REMOTE WITH CONNECTION `us.llm`\n",
    "OPTIONS (endpoint = 'https://aiplatform.googleapis.com/v1/projects/dataml-latam-argolis/locations/global/publishers/google/models/gemini-3-pro-preview')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "1afacad0721445c0b8bc9930d3a8e6fd",
      "81fa2bd8eb0344f4b3978f48d65406dc",
      "8ec0cfc4775a4acca03b294fafb49488",
      "dd4029ab7b4a47d4970ec1db7065c404",
      "9447800672aa455e89d03c89603ed005",
      "7bebaa87bf4147cc9205c0c9b0997ae6",
      "4557e2b477974322884826621cff40e6",
      "b0728578cddd4bdb8fd580a1f53a145f",
      "444eb77a315e42ce8d068932b618ff52",
      "b01ed4210439488b9d02b39ab873ef3f",
      "d057a3744772409eb46dc82f68c5920c"
     ]
    },
    "id": "zosT7kTBvz40",
    "outputId": "aac75f92-7cdd-4ef7-9a1c-accfb4900a0c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_a9YsOPe4yje",
    "outputId": "670bbd43-c32f-4e4e-a23a-8398231c6559"
   },
   "outputs": [],
   "source": [
    "# Summarize findings for Gemini\n",
    "summary_text = f'''\n",
    "Audit Findings for Resource Management:\n",
    "1. Pricing Model: Analyzed {len(df_pricing)} queries. Found {len(df_pricing[df_pricing['recommendation'] == 'SWITCH_TO_SLOTS'])} queries where switching to Slots is recommended.\n",
    "2. Contention: Found {len(df_contention)} projects with significant pending time.\n",
    "3. Slot Usage: Max slots per minute is {df_max_autoscaling['max_slots_per_minute'].iloc[0] if not df_max_autoscaling.empty else 'N/A'}, Average slots per minute is {df_max_autoscaling['avg_slots_per_minute_total'].iloc[0] if not df_max_autoscaling.empty else 'N/A'}.\n",
    "4. Errors: Top error is {df_errors['error_reason'].iloc[0] if not df_errors.empty else 'None'}.\n",
    "5. Google Cloud Recommendations: Found {len(df_recommendations)} active capacity recommendations.\n",
    "'''\n",
    "\n",
    "# Construct the prompt\n",
    "prompt = f\"Analyze the following metrics regarding BigQuery Resource Management and provide 3 actionable recommendations. Context: {summary_text}\"\n",
    "\n",
    "# Escape single quotes in prompt for BigQuery SQL literal\n",
    "escaped_prompt = prompt.replace(\"'\", \"\\'\")\n",
    "\n",
    "# Call Gemini via BQML\n",
    "query_gemini = f\"\"\"\n",
    "SELECT\n",
    "  ml_generate_text_result['candidates'][0]['content'] AS recommendation\n",
    "FROM\n",
    "  ML.GENERATE_TEXT(\n",
    "    MODEL `{PROJECT_ID}.bq_bestpractices_checklist.gemini`,\n",
    "    (SELECT '''{escaped_prompt}''' AS prompt),\n",
    "    STRUCT(\n",
    "      0.2 AS temperature,\n",
    "      8192 AS max_output_tokens\n",
    "    )\n",
    "  )\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df_gemini = client.query(query_gemini).to_dataframe()\n",
    "    print(\"AI-Powered Recommendations:\")\n",
    "    for index, row in df_gemini.iterrows():\n",
    "        print(row['recommendation'])\n",
    "except Exception as e:\n",
    "    print(\"Error calling Gemini. Ensure the model exists and you have permissions.\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1afacad0721445c0b8bc9930d3a8e6fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_81fa2bd8eb0344f4b3978f48d65406dc",
       "IPY_MODEL_8ec0cfc4775a4acca03b294fafb49488",
       "IPY_MODEL_dd4029ab7b4a47d4970ec1db7065c404"
      ],
      "layout": "IPY_MODEL_9447800672aa455e89d03c89603ed005"
     }
    },
    "81fa2bd8eb0344f4b3978f48d65406dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7bebaa87bf4147cc9205c0c9b0997ae6",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_4557e2b477974322884826621cff40e6",
      "value": "Job\u2007ID\u2007ad6668e1-603f-442b-9912-d05be1f1c0dc\u2007successfully\u2007executed:\u2007100%"
     }
    },
    "8ec0cfc4775a4acca03b294fafb49488": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0728578cddd4bdb8fd580a1f53a145f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_444eb77a315e42ce8d068932b618ff52",
      "value": 1
     }
    },
    "dd4029ab7b4a47d4970ec1db7065c404": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b01ed4210439488b9d02b39ab873ef3f",
      "placeholder": "\u200b",
      "style": "IPY_MODEL_d057a3744772409eb46dc82f68c5920c",
      "value": ""
     }
    },
    "9447800672aa455e89d03c89603ed005": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bebaa87bf4147cc9205c0c9b0997ae6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4557e2b477974322884826621cff40e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0728578cddd4bdb8fd580a1f53a145f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "444eb77a315e42ce8d068932b618ff52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b01ed4210439488b9d02b39ab873ef3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d057a3744772409eb46dc82f68c5920c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}